# Chapter 1 计算机系统漫游

## 1.5 Caches matter

SRAM：The L1 and L2 caches are implemented with a hardware technology known
as *static random access memory* (SRAM).

## 1.7 The Operating System Manages the Hardware

![Abstractions provided by an operating system](Chapter%201%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8%204999c1fac43f47dba6591970f3e85a17/Untitled.png)

Abstractions provided by an operating system

files are abstractions for I/O devices, virtual memory is an abstraction for both the main memory and disk I/O devices, and processes are abstractions for the processor, main memory, and I/O devices.

### **1.7.1 Processes 进程**

线程是操作系统对于运行程序的一个抽象。在同一个操作系统中可以并行运行多个线程，这些线程看上去都如同是独占硬件。
This state, which is known as the *context*, includes information such as the current values of the PC, the register file, and the contents of main memory.
线程切换依靠的是操作系统内核，但内核并不是一个独立的线程，是操作系统中管理线程的一段代码和数据结构。

### 1.7.2 Threads 线程

进程可能包含多个线程。线程共享数据和内存

### 1.7.3 Virtual Memory

虚拟内存是一个让线程感觉是独占主内存的抽象。

顶部是系统代码，底部是进程自有的数据和代码。由底至上主要包括如下：

- 程序代码和数据：所有进程内存起点都一致，先是全局变量，接着是从OBJ文件初始化的代码和变量，也叫**装载** 这部分大小在进程启动后就固定了
- 堆：这部分大小是动态的，会依据C程序中`malloc`和`free`的调用改变
- 共享库：保存C程序中调用的共享库的代码。这部分共享库的重定位很重要，称**动态链接**
- 栈：用户空间顶部是栈，用来实施函数的调用。大小也是**动态**的，随着函数调用增加，函数返回减少
- 内核虚拟内存：最顶部的系统内核保留区，应用不能直接调用，需要通过内核调用。

![**Process virtual address space**](Chapter%201%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8%204999c1fac43f47dba6591970f3e85a17/Untitled%201.png)

**Process virtual address space**

### 1.7.4 Files

文件是字节的序列。所有的IO设备都可以**抽象**看作是文件。“一切皆文件”
****

## 1.8 Systems Communicate with Other Systems Using Networks 系统间的网络通信

网络也可以被抽象称文件：系统直接的字节流

![Untitled](Chapter%201%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%BC%AB%E6%B8%B8%204999c1fac43f47dba6591970f3e85a17/Untitled%202.png)

这个抽象真是很厉害了。👍 例如通过`Telnet`在 远程机器运行hello程序

### **1.9.2 Concurrency and Parallelism**

We use the term *concurrency* to refer to the general concept of a system with multiple, simultaneous activities, and the term *parallelism* to refer to the use of concurrency to make a system run faster.